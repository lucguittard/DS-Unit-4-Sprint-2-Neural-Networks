{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(([0,0,1],\n",
    "             [0,1,1],\n",
    "             [1,0,1],\n",
    "             [0,1,0],\n",
    "             [1,0,0],\n",
    "             [1,1,1],\n",
    "             [0,0,0]),\n",
    "            dtype = float)\n",
    "\n",
    "y = np.array(([0],[1],[1],[1],[1],[0],[0]),\n",
    "             dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.input = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # Initial Weights\n",
    "        # 2x3 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.randn(self.input,self.hiddenNodes)\n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs & hidden\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final Activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n",
      "output [0.6528385]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "print(X[0])\n",
    "output = nn.feed_forward(X[0])\n",
    "print(\"output\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6528385])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y[0] - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6528385 ]\n",
      " [0.60338374]\n",
      " [0.64069627]\n",
      " [0.59295516]\n",
      " [0.62904358]\n",
      " [0.59638406]\n",
      " [0.64437712]]\n",
      "[[-0.6528385 ]\n",
      " [ 0.39661626]\n",
      " [ 0.35930373]\n",
      " [ 0.40704484]\n",
      " [ 0.37095642]\n",
      " [-0.59638406]\n",
      " [-0.64437712]]\n"
     ]
    }
   ],
   "source": [
    "output_all = nn.feed_forward(X)\n",
    "error_all = y - output_all\n",
    "print(output_all)\n",
    "print(error_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated_hidden\n",
      " [[0.6228877  0.55068571 0.03242881 0.35159744]\n",
      " [0.06612507 0.99552333 0.0495059  0.99360595]\n",
      " [0.99724101 0.07010318 0.05629717 0.99273501]\n",
      " [0.04110634 0.99451887 0.60846196 0.99652264]\n",
      " [0.99545107 0.05794621 0.64027886 0.9960474 ]\n",
      " [0.93937513 0.93187428 0.08484128 0.99997446]\n",
      " [0.5        0.5        0.5        0.5       ]] \n",
      "---------\n",
      "activated_output\n",
      " [[0.00668251]\n",
      " [0.95688551]\n",
      " [0.95951367]\n",
      " [0.95017315]\n",
      " [0.94837986]\n",
      " [0.04770098]\n",
      " [0.09080583]] \n",
      "---------\n",
      "hidden_sum\n",
      " [[ 0.50182323  0.20344165 -3.39574177 -0.61202484]\n",
      " [-2.64779455  5.40439019 -2.95489005  5.04597241]\n",
      " [ 5.89012756 -2.58510551 -2.81916707  4.91739625]\n",
      " [-3.14961778  5.20094854  0.44085172  5.65799725]\n",
      " [ 5.38830433 -2.78854716  0.5765747   5.52942109]\n",
      " [ 2.74050978  2.61584303 -2.37831535 10.5753935 ]\n",
      " [ 0.          0.          0.          0.        ]] \n",
      "---------\n",
      "weights1\n",
      " [[ 5.38912202 -2.78934276  0.57623405  5.52966329]\n",
      " [-3.15022117  5.20185129  0.4405247   5.65821873]\n",
      " [ 0.50197253  0.20373604 -3.39574014 -0.61188255]] \n",
      "---------\n",
      "weights2\n",
      " [[-7.59868341]\n",
      " [-7.73203543]\n",
      " [-0.68561592]\n",
      " [11.40729475]] \n",
      "---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find which layer is producing poor weights\n",
    "attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'activated_output','output']\n",
    "\n",
    "[print(i + '\\n', getattr(nn,i), '\\n'+'---'*3) for i in dir(nn) if i in attributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low predictions? -> Try increasing weights in either layer. Biggest positive effect from increasing weights in places where there are already high activation values. Decrease activations that correspond to negative weights and increase activations corresponding with positive weights. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.48930052]\n",
      " [0.21807986]\n",
      " [0.18634985]\n",
      " [0.09920813]\n",
      " [0.08222238]\n",
      " [0.09470159]\n",
      " [0.24229641]]\n",
      "Loss: \n",
      " 0.4620369109517397\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.56174119]\n",
      " [0.32733081]\n",
      " [0.27174338]\n",
      " [0.15120005]\n",
      " [0.11968984]\n",
      " [0.15147074]\n",
      " [0.30068107]]\n",
      "Loss: \n",
      " 0.4153077902252257\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.63985006]\n",
      " [0.47631123]\n",
      " [0.3923817 ]\n",
      " [0.23723216]\n",
      " [0.18080498]\n",
      " [0.25478594]\n",
      " [0.37775379]]\n",
      "Loss: \n",
      " 0.35905244033838646\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.70105735]\n",
      " [0.60780749]\n",
      " [0.50884201]\n",
      " [0.34365765]\n",
      " [0.25934963]\n",
      " [0.388056  ]\n",
      " [0.45644236]]\n",
      "Loss: \n",
      " 0.31782969605410155\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.73161788]\n",
      " [0.67758359]\n",
      " [0.57799821]\n",
      " [0.42838758]\n",
      " [0.32822978]\n",
      " [0.48658942]\n",
      " [0.51245077]]\n",
      "Loss: \n",
      " 0.29924194577660923\n",
      "+---------EPOCH 50---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.49964099]\n",
      " [0.55347015]\n",
      " [0.53838127]\n",
      " [0.67272057]\n",
      " [0.6756637 ]\n",
      " [0.59545653]\n",
      " [0.61547548]]\n",
      "Loss: \n",
      " 0.22968661208283164\n",
      "+---------EPOCH 100---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.33968134]\n",
      " [0.57179158]\n",
      " [0.58989766]\n",
      " [0.7260414 ]\n",
      " [0.74802825]\n",
      " [0.63225153]\n",
      " [0.51968332]]\n",
      "Loss: \n",
      " 0.1821836585212928\n",
      "+---------EPOCH 150---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.20599153]\n",
      " [0.63117413]\n",
      " [0.63353171]\n",
      " [0.77361241]\n",
      " [0.77530369]\n",
      " [0.6043205 ]\n",
      " [0.41966788]]\n",
      "Loss: \n",
      " 0.13654688590423184\n",
      "+---------EPOCH 200---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.14466263]\n",
      " [0.67854799]\n",
      " [0.69040563]\n",
      " [0.78010655]\n",
      " [0.77342331]\n",
      " [0.54278048]\n",
      " [0.36269874]]\n",
      "Loss: \n",
      " 0.10656549991956112\n",
      "+---------EPOCH 250---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.10162827]\n",
      " [0.71634069]\n",
      " [0.75965192]\n",
      " [0.81245985]\n",
      " [0.77837791]\n",
      " [0.4284281 ]\n",
      " [0.32126883]]\n",
      "Loss: \n",
      " 0.07423000920114865\n",
      "+---------EPOCH 300---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.06336563]\n",
      " [0.78436978]\n",
      " [0.83099766]\n",
      " [0.86528538]\n",
      " [0.83771104]\n",
      " [0.26606928]\n",
      " [0.26486252]]\n",
      "Loss: \n",
      " 0.03778630505824935\n",
      "+---------EPOCH 350---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.04176204]\n",
      " [0.84336056]\n",
      " [0.87176357]\n",
      " [0.89438933]\n",
      " [0.87970477]\n",
      " [0.17694842]\n",
      " [0.21605892]]\n",
      "Loss: \n",
      " 0.020905902818763637\n",
      "+---------EPOCH 400---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.03056064]\n",
      " [0.87712044]\n",
      " [0.89512133]\n",
      " [0.90924396]\n",
      " [0.89973879]\n",
      " [0.13486653]\n",
      " [0.18458502]]\n",
      "Loss: \n",
      " 0.013940350690140069\n",
      "+---------EPOCH 450---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.02395966]\n",
      " [0.89768953]\n",
      " [0.91025193]\n",
      " [0.91834624]\n",
      " [0.91134649]\n",
      " [0.1111632 ]\n",
      " [0.16361565]]\n",
      "Loss: \n",
      " 0.01039290461779333\n",
      "+---------EPOCH 500---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.01964194]\n",
      " [0.91148073]\n",
      " [0.92093181]\n",
      " [0.92470675]\n",
      " [0.91917139]\n",
      " [0.09586702]\n",
      " [0.14861227]]\n",
      "Loss: \n",
      " 0.008278811003430281\n",
      "+---------EPOCH 550---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.01660485]\n",
      " [0.92141789]\n",
      " [0.9289242 ]\n",
      " [0.92953022]\n",
      " [0.92495697]\n",
      " [0.08507803]\n",
      " [0.13723538]]\n",
      "Loss: \n",
      " 0.006881700765857747\n",
      "+---------EPOCH 600---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.0143545 ]\n",
      " [0.92896072]\n",
      " [0.93516237]\n",
      " [0.93338678]\n",
      " [0.92949384]\n",
      " [0.07699569]\n",
      " [0.12822424]]\n",
      "Loss: \n",
      " 0.005890682896602178\n",
      "+---------EPOCH 650---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.0126212 ]\n",
      " [0.93491112]\n",
      " [0.94018798]\n",
      " [0.93658383]\n",
      " [0.93319641]\n",
      " [0.07067571]\n",
      " [0.12084843]]\n",
      "Loss: \n",
      " 0.005151009168779855\n",
      "+---------EPOCH 700---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.01124563]\n",
      " [0.93974542]\n",
      " [0.94433785]\n",
      " [0.93930406]\n",
      " [0.93630599]\n",
      " [0.06557374]\n",
      " [0.11465626]]\n",
      "Loss: \n",
      " 0.004577464709371816\n",
      "+---------EPOCH 750---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.01012775]\n",
      " [0.9437647 ]\n",
      " [0.94783286]\n",
      " [0.9416643 ]\n",
      " [0.93897445]\n",
      " [0.06135265]\n",
      " [0.10935289]]\n",
      "Loss: \n",
      " 0.004119394806913509\n",
      "+---------EPOCH 800---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.00920159]\n",
      " [0.94716897]\n",
      " [0.95082422]\n",
      " [0.9437436 ]\n",
      " [0.94130313]\n",
      " [0.05779169]\n",
      " [0.10473704]]\n",
      "Loss: \n",
      " 0.003744839605047303\n",
      "+---------EPOCH 850---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.00842196]\n",
      " [0.95009655]\n",
      " [0.95341907]\n",
      " [0.9455979 ]\n",
      " [0.94336281]\n",
      " [0.05473976]\n",
      " [0.10066623]]\n",
      "Loss: \n",
      " 0.0034326511452358673\n",
      "+---------EPOCH 900---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.0077568 ]\n",
      " [0.95264634]\n",
      " [0.95569559]\n",
      " [0.94726815]\n",
      " [0.94520481]\n",
      " [0.05208966]\n",
      " [0.09703638]]\n",
      "Loss: \n",
      " 0.0031682812843526914\n",
      "+---------EPOCH 950---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.00718278]\n",
      " [0.95489108]\n",
      " [0.95771225]\n",
      " [0.94878528]\n",
      " [0.9468674 ]\n",
      " [0.04976298]\n",
      " [0.0937695 ]]\n",
      "Loss: \n",
      " 0.0029413937151926183\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.00668251]\n",
      " [0.95688551]\n",
      " [0.95951367]\n",
      " [0.95017315]\n",
      " [0.94837986]\n",
      " [0.04770098]\n",
      " [0.09080583]]\n",
      "Loss: \n",
      " 0.0027444419418021604\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "# Train the nn over 1000 epochs \n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
    "\n",
    "\n",
    "### Parts\n",
    "1. Gathering & Transforming the Data\n",
    "2. Making MNIST a Binary Problem\n",
    "3. Estimating your Neural Network (the part you focus on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the Data \n",
    "\n",
    "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/72/6b3264aa2889b7dde7663464b99587d95cd6a5f3b9b30181f14d78a63e64/tensorflow-2.0.0-cp37-cp37m-macosx_10_11_x86_64.whl (102.7MB)\n",
      "\u001b[K     |████████████████████████████████| 102.7MB 687kB/s eta 0:00:01    |████████                        | 25.4MB 690kB/s eta 0:01:52     |█████████████████               | 54.4MB 654kB/s eta 0:01:14     |█████████████████▋              | 56.7MB 849kB/s eta 0:00:55     |█████████████████████▉          | 70.1MB 885kB/s eta 0:00:37     |██████████████████████████▍     | 84.7MB 845kB/s eta 0:00:22     |█████████████████████████████▎  | 93.9MB 657kB/s eta 0:00:14     |██████████████████████████████▏ | 97.0MB 611kB/s eta 0:00:10     |██████████████████████████████▋ | 98.3MB 620kB/s eta 0:00:08\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 615kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 880kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 135kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 839kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/22/c462571c795d7071847f1046fbdb43c03ec1b358948c2c83ff56691e5a32/grpcio-1.24.3-cp37-cp37m-macosx_10_9_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 732kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c6/a8b6a74ab1e165f0aaa673a46f5c895af8780976880c98934ae82060356d/protobuf-3.10.0-cp37-cp37m-macosx_10_9_intel.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 758kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 728kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 858kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.4.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/81/d1e7d9974ba7c886f6d133a8baae18cb8d92b2d09bcc4f46328306825de0/google_auth-1.7.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 806kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/Person/anaconda3/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.15.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 842kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<3.2,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 751kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 681kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 662kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /Users/Person/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Person/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Person/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Person/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Person/anaconda3/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
      "Building wheels for collected packages: gast, absl-py, opt-einsum\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Person/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Person/Library/Caches/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Person/Library/Caches/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "Successfully built gast absl-py opt-einsum\n",
      "Installing collected packages: tensorflow-estimator, keras-applications, keras-preprocessing, google-pasta, protobuf, absl-py, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, grpcio, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, astor, gast, termcolor, opt-einsum, tensorflow\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 gast-0.2.2 google-auth-1.7.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.24.3 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.10.0 pyasn1-0.4.7 pyasn1-modules-0.2.7 requests-oauthlib-1.2.0 rsa-4.0 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
    "\n",
    "# Normalize Our Data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the data should be in a format you're more familiar with\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making MNIST a Binary Problem \n",
    "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simply the problem for now: Zero or all else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = np.zeros(y_train.shape)\n",
    "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
    "y_train = y_temp\n",
    "\n",
    "y_temp = np.zeros(y_test.shape)\n",
    "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
    "y_test = y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Nice Binary target for ya to work with\n",
    "y_train\n",
    "\n",
    "# ..nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   779  780  781  782  783  0    \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(x_train)\n",
    "y = pd.DataFrame(y_train)\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Your `net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    "\n",
    "dataset = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=975.000\n",
      ">epoch=1, lrate=0.100, error=775.000\n",
      ">epoch=2, lrate=0.100, error=728.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c71230012d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c71230012d24>\u001b[0m in \u001b[0;36mtrain_weights\u001b[0;34m(train, l_rate, n_epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>epoch=%d, lrate=%.3f, error=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Estimate Perceptron weights using stochastic gradient descent\n",
    "def train_weights(train, l_rate, n_epoch):\n",
    "    weights = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            prediction = predict(row, weights)\n",
    "            error = row[-1] - prediction\n",
    "            sum_error += error**2\n",
    "            weights[0] = weights[0] + l_rate * error\n",
    "            for i in range(len(row)-1):\n",
    "                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return weights\n",
    "\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "weight = train_weights(dataset, l_rate, n_epoch)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 533kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/Person/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label shape:  (60000,)\n",
      "First 5 training labels:  [5 0 4 1 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Setup train and test splits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"Training label shape: \", y_train.shape) # (60000,) -- 60000 numbers (all 0-9)\n",
    "print(\"First 5 training labels: \", y_train[:5]) # [5, 0, 4, 1, 9]\n",
    "\n",
    "# Convert to \"one-hot\" vectors using the to_categorical function\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Another method:\n",
    "\n",
    "from keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
    "from keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
    "\n",
    "image_size = 784 # 28*28\n",
    "num_classes = 10 # ten unique digits\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer requires the special input_shape parameter which should match\n",
    "# the shape of our training data.\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.306\n",
      "Test accuracy: 0.918\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=False, validation_split=.1)\n",
    "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at effect of hidden-layer depth\n",
    "\n",
    "def create_dense(layer_sizes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], activation='sigmoid', input_shape=(image_size,)))\n",
    "\n",
    "    for s in layer_sizes[1:]:\n",
    "        model.add(Dense(units = s, activation = 'sigmoid'))\n",
    "\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, batch_size=100, epochs=20):\n",
    "    model.summary()\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
    "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.285\n",
      "Test accuracy: 0.918\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-6c909b42ffdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-4691e24fb739>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, batch_size, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \"\"\"\n\u001b[1;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3497\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3405\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3551\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3552\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for layers in range(1, 5):\n",
    "    model = create_dense([32] * layers)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.298\n",
      "Test accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Single hidden-layer accuracy levels are best.\n",
    "#  Look at epochs in greater depth for this model. \n",
    "for layers in range(1,2):\n",
    "    model = create_dense([32] * layers)\n",
    "    evaluate(model)\n",
    "    \n",
    "# Five epochs seems sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's some impressive accuracy. Can also fiddle with batch-size, the layer depth and the number of nodes per layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
